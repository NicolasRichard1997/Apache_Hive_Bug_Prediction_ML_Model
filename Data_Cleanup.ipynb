{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup\n",
    "\n",
    "This notebook contains all the steps necessary to associate classes and methods in UND data collected before and to identify files with bugs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing UND Data\n",
    "\n",
    "First, we will get rid of the all the classes and methods in each entry into the CSV and a 'Bug' column initialized at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Files saved: ['/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.8_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.2.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-4.0.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.3_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-3.1.3_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.7_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.10_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.1.1_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.5_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-3.1.2_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.0.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-4.0.1_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.2_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.9_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-3.1.1_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.1.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.1_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.4_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.3.6_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-3.1.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-3.0.0_processed.csv', '/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/UND_hive_processed_data/UND_hive-2.0.1_processed.csv']\n"
     ]
    }
   ],
   "source": [
    "def process_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    df = df[df['Kind'] == 'File']\n",
    "\n",
    "    df = df.drop(columns=['Kind','Entity_Uniquename'])  \n",
    "    df.insert(0, 'Bug', 0)  \n",
    "    \n",
    "    df = df.rename(columns={'Name': 'FileName'})\n",
    "    \n",
    "    columns_order = ['Bug', 'FileName'] + [col for col in df.columns if col not in ['Bug', 'FileName']]\n",
    "    df = df[columns_order]\n",
    "    \n",
    "    return df\n",
    "\n",
    "current_repo = os.getcwd()\n",
    "input_files = glob.glob(os.path.join(current_repo, 'UND_hive_data', '*.csv'))\n",
    "output_dir = os.path.join(current_repo, 'UND_hive_processed_data')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_files = []\n",
    "\n",
    "for file_path in input_files:\n",
    "    processed_df = process_csv(file_path)\n",
    "\n",
    "    base_name = os.path.basename(file_path) \n",
    "    output_file = os.path.join(output_dir, base_name.replace('.csv', '_processed.csv'))\n",
    "    processed_df.to_csv(output_file, index=False)\n",
    "    output_files.append(output_file)\n",
    "\n",
    "print(\"Processing complete. Files saved:\", output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify Files with Bugs\n",
    "\n",
    "For each of the affected files identified in the previous notebook, we will initialize at '1' the bug column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Bug ID  Version                                               File\n",
      "0         Bug_ID  Version                                   Affected_File(s)\n",
      "1     HIVE-19247    2.2.0  ql/src/java/org/apache/hadoop/hive/ql/optimize...\n",
      "2     HIVE-19085    2.3.2  storage-api/src/java/org/apache/hadoop/hive/co...\n",
      "3     HIVE-18611    2.3.2  ql/src/java/org/apache/hadoop/hive/ql/optimize...\n",
      "4     HIVE-18611    2.3.2  ql/src/java/org/apache/hadoop/hive/ql/udf/gene...\n",
      "...          ...      ...                                                ...\n",
      "2651   HIVE-7239    2.1.0  ql/src/test/org/apache/hadoop/hive/ql/index/Mo...\n",
      "2652   HIVE-7239    2.1.0  ql/src/test/org/apache/hadoop/hive/ql/index/Mo...\n",
      "2653   HIVE-7239    2.1.0  ql/src/test/org/apache/hadoop/hive/ql/index/Sp...\n",
      "2654   HIVE-7239    2.1.0  ql/src/test/org/apache/hadoop/hive/ql/index/Te...\n",
      "2655   HIVE-7239    2.1.0  ql/src/test/org/apache/hadoop/hive/ql/index/Te...\n",
      "\n",
      "[2656 rows x 3 columns]\n",
      "Percentage of files found: -76.12951807228916%\n"
     ]
    }
   ],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "input_file = 'Hive_Affected_Files.csv'  \n",
    "\n",
    "bug_ids = []\n",
    "versions = []\n",
    "file_names = []\n",
    "\n",
    "with open(input_file, 'r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        bug_id = row[0]\n",
    "        version = row[1]\n",
    "\n",
    "        affected_files = row[2].split(';')\n",
    "\n",
    "        for file in affected_files:\n",
    "            bug_ids.append(bug_id)\n",
    "            versions.append(version)\n",
    "            file_names.append(file)\n",
    "\n",
    "output_df = pd.DataFrame({\n",
    "    'Bug ID': bug_ids,\n",
    "    'Version': versions,\n",
    "    'File': file_names\n",
    "})\n",
    "\n",
    "print(output_df)\n",
    "\n",
    "unfound_bug_ids = []\n",
    "unfound_versions = []\n",
    "unfound_file_names = []\n",
    "\n",
    "for index, row in output_df.iloc[1:].iterrows():\n",
    "    filename = f\"{current_repo}/UND_hive_processed_data/UND_hive-{row['Version']}_processed.csv\"\n",
    "    target_file = row['File'] \n",
    "\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    found = False\n",
    "\n",
    "for i, columns in enumerate(rows):\n",
    "    if len(columns) > 1:\n",
    "        file_name_in_row = columns[1].strip().removeprefix(\"/home/nicolas-richard/Desktop/.Apache_Hive/\")\n",
    "\n",
    "        file_name_in_row_lower = file_name_in_row.lower()\n",
    "        target_file_lower = target_file.lower()\n",
    "\n",
    "        if (target_file_lower in file_name_in_row_lower or \n",
    "            file_name_in_row_lower in target_file_lower or\n",
    "            target_file_lower.replace('/', '\\\\') in file_name_in_row_lower or\n",
    "            file_name_in_row_lower.replace('/', '\\\\') in target_file_lower or\n",
    "            target_file_lower.split('.')[0] in file_name_in_row_lower or\n",
    "            file_name_in_row_lower.split('.')[0] in target_file_lower):\n",
    "            \n",
    "            columns[0] = '1'\n",
    "            rows[i] = columns\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        unfound_bug_ids.append(row['Bug ID'])\n",
    "        unfound_versions.append(row['Version'])\n",
    "        unfound_file_names.append(row['File'])\n",
    "    else:\n",
    "        with open(filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(rows)\n",
    "\n",
    "percentageBug_files_found = 100 - ((len(unfound_bug_ids)/(len(bug_ids))) * 100)\n",
    "\n",
    "print(f\"Percentage of files found: {percentageBug_files_found}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 13% of affected files were not found, all versions considered, with possible reasons including file path changes or reorganization, files being deleted or moved, different naming conventions across versions, case sensitivity issues in filenames, file permissions or access issues, files being renamed during updates, incorrect path mappings, files being archived or compressed, files being merged or split into other files, and documentation/reference errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
