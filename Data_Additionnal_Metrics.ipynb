{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionnal Metrics\n",
    "As per the specification of the personnal project, we'll try and gather additionnal metrics to improve our model. Since this notebook is very compute-intensive, it was executed directly in the terminal after converting this notebook to a python file.\n",
    "## 1. Lines added & deleted from a given version\n",
    "We'll begin by creating a dictionnary of versions and corresponding commits from the file `Hive_Last_Commits.csv`previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import git\n",
    "import glob\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "from functools import lru_cache\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "from typing import Dict, Iterable, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_repo = Path(\"/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model\")\n",
    "hive_repo = Path(\"/home/nicolas-richard/Desktop/.Apache_Hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2.0.0   ': ['7f9f1fcb8697fb33f0edc2c391930a3728d247d7'], '2.0.1   ': ['e3cfeebcefe9a19c5055afdcbb00646908340694'], '2.1.0   ': ['9265bc24d75ac945bde9ce1a0999fddd8f2aae29'], '2.1.1   ': ['1af77bbf8356e86cabbed92cfa8cc2e1470a1d5c'], '2.2.0   ': ['da840b0f8fa99cab9f004810cd22abc207493cae'], '2.3.0   ': ['6f4c35c9e904d226451c465effdc5bfd31d395a0'], '2.3.1   ': ['7590572d9265e15286628013268b2ce785c6aa08'], '2.3.2   ': ['857a9fd8ad725a53bd95c1b2d6612f9b1155f44d'], '2.3.3   ': ['3f7dde31aed44b5440563d3f9d8a8887beccf0be'], '2.3.4   ': ['56acdd2120b9ce6790185c679223b8b5e884aaf2'], '2.3.5   ': ['76595628ae13b95162e77bba365fe4d2c60b3f29'], '2.3.6   ': ['2c2fdd524e8783f6e1f3ef15281cc2d5ed08728f'], '2.3.7   ': ['cb213d88304034393d68cc31a95be24f5aac62b6'], '2.3.8   ': ['f1e87137034e4ecbe39a859d4ef44319800016d7'], '2.3.9   ': ['92dd0159f440ca7863be3232f3a683a510a62b9d'], '2.3.10  ': ['5160d3af392248255f68e41e1e0557eae4d95273'], '3.0.0   ': ['ce61711a5fa54ab34fc74d86d521ecaeea6b072a'], '3.1.0   ': ['bcc7df95824831a8d2f1524e4048dfc23ab98c19'], '3.1.1   ': ['f4e0529634b6231a0072295da48af466cf2f10b7'], '3.1.2   ': ['8190d2be7b7165effa62bd21b7d60ef81fb0e4af'], '3.1.3   ': ['4df4d75bf1e16fe0af75aad0b4179c34c07fc975'], '4.0.0   ': ['183f8cb41d3dbed961ffd27999876468ff06690c'], '4.0.1   ': ['3af4517eb8cfd9407ad34ed78a0b48b57dfaa264']}\n"
     ]
    }
   ],
   "source": [
    "last_commits = open(os.path.join(project_repo, \"Hive_Last_Commits.csv\"), \"r\")\n",
    "\n",
    "\n",
    "\n",
    "versions = []\n",
    "commits_by_version = {}\n",
    "\n",
    "for i, line in enumerate(last_commits.readlines()):\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    parts = line.strip().split(\",\")\n",
    "    version = parts[0]\n",
    "    commit = parts[1]\n",
    "\n",
    "    versions.append(version)\n",
    "    commits_by_version[version] = [commit]  \n",
    "last_commits.close()\n",
    "\n",
    "print(commits_by_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UND_hive_updated_directory = project_repo / \"UND_hive_updated_data\"\n",
    "output_directory = project_repo / \"UND_hive_additional_metrics\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(UND_hive_updated_directory) if f.endswith('.csv')])\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(UND_hive_updated_directory / file)\n",
    "    df_version = file.split(\"_\")[1]\n",
    "\n",
    "    print(f\"\\n=== Processing version: {df_version} ===\")\n",
    "\n",
    "    for another_file in csv_files:\n",
    "        another_version = another_file.split(\"_\")[1]\n",
    "    \n",
    "        df[f\"LinesAddedSince{another_version}\"] = 0\n",
    "        print(f\"LinesAddedSince{another_version} added to version {df_version}\")\n",
    "        df[f\"LinesRemovedSince{another_version}\"] = 0\n",
    "        print(f\"LinesRemovedSince{another_version} added to version {df_version}\")\n",
    "\n",
    "        if another_version >= df_version: \n",
    "            continue\n",
    "            \n",
    "        print(f\"  Comparing with earlier version: {another_version}\")\n",
    "        another_df = pd.read_csv(os.path.join(UND_hive_updated_directory, another_file))\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            file_name = row[\"FileName\"]\n",
    "            line_count = row[\"CountLine\"]\n",
    "\n",
    "            matching_rows = another_df[another_df[\"FileName\"] == file_name]\n",
    "\n",
    "            if not matching_rows.empty:\n",
    "                another_line_count = matching_rows.iloc[0][\"CountLine\"]\n",
    "                print(f\"    - {file_name} found in version {another_version}\")\n",
    "\n",
    "                if line_count > another_line_count:\n",
    "                    added_lines = line_count - another_line_count\n",
    "                    df.loc[index, f\"LinesAddedSince{another_version}\"] = added_lines\n",
    "                    print(f\"      Lines added: {added_lines}\")\n",
    "                elif line_count < another_line_count:\n",
    "                    removed_lines = another_line_count - line_count\n",
    "                    df.loc[index, f\"LinesRemovedSince{another_version}\"] = removed_lines\n",
    "                    print(f\"      Lines removed: {removed_lines}\")\n",
    "\n",
    "    output_path = output_directory / f\"UND_{df_version}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"=== Updated file saved as {output_path} ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Commits Affecting each File, Developper Experience and Comparison with Previous Versions\n",
    "In this section, we'll define functions to generate the metrics for commits affecting the file, developpers having worked on the project and their expertise. Here are the metrics, their definition and their collection method we aim to gather for each file/version:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "1. Number of Commits Affecting File in Version (`num_commits_in_version`)\n",
    "\n",
    "    Definition: Total number of commits that have modified the target file in the current version.\n",
    "    Collection Method:\n",
    "        Fetch all commits that have affected the target file across all versions.\n",
    "        Map each commit to its respective version based on the commit ranges defined between version tags.\n",
    "        Count the number of commits affecting the file in the current version.\n",
    "\n",
    "2. Number of Bug Fix Commits in Version (`num_bug_fix_commits`)\n",
    "\n",
    "    Definition: Number of commits in the current version that address bug fixes in the target file.\n",
    "    Collection Method:\n",
    "        From the commits affecting the file in the current version, identify commits with messages containing bug fix keywords (e.g., \"fix\", \"bug\", \"issue\", \"HIVE-\").\n",
    "        Count these bug fix commits.\n",
    "\n",
    "3. Number of Commits in Previous Versions (`num_commits_in_previous_versions`)\n",
    "\n",
    "    Definition: Total number of commits that have modified the target file in all versions prior to the current version.\n",
    "    Collection Method:\n",
    "        Aggregate commits affecting the file from all previous versions.\n",
    "        Count the total number of these commits.\n",
    "\n",
    "4. Number of Developers in Version (`num_developers_in_version`)\n",
    "\n",
    "    Definition: Number of unique developers who have committed changes to the target file in the current version.\n",
    "    Collection Method:\n",
    "        Extract the email addresses of authors from the commits affecting the file in the current version.\n",
    "        Count the number of unique developer emails.\n",
    "\n",
    "5. Number of Developers in Previous Versions (`num_developers_in_previous_versions`)\n",
    "\n",
    "    Definition: Number of unique developers who have committed changes to the target file in all previous versions.\n",
    "    Collection Method:\n",
    "        Extract the email addresses of authors from the commits affecting the file in previous versions.\n",
    "        Count the number of unique developer emails.\n",
    "\n",
    "6. Average Expertise in Version (`avg_expertise_in_version`)\n",
    "\n",
    "    Definition: The average total number of commits made by developers (across the entire repository) who have contributed to the target file in the current version.\n",
    "    Collection Method:\n",
    "        For each developer who committed to the file in the current version, retrieve their total number of commits in the entire repository (developer experience).\n",
    "        Calculate the average of these totals.\n",
    "\n",
    "7. Average Expertise in Previous Versions (`avg_expertise_in_previous_versions`)\n",
    "\n",
    "    Definition: The average total number of commits made by developers who have contributed to the target file in previous versions.\n",
    "    Collection Method:\n",
    "        For each developer from previous versions, retrieve their total number of commits in the entire repository.\n",
    "        Calculate the average of these totals.\n",
    "\n",
    "8. Minimum Expertise in Version (`min_expertise_in_version`)\n",
    "\n",
    "    Definition: The smallest total number of commits (in the entire repository) among developers who have contributed to the target file in the current version.\n",
    "    Collection Method:\n",
    "        Retrieve the total commits for each developer in the current version.\n",
    "        Identify the minimum total commits among them.\n",
    "\n",
    "9. Minimum Expertise in Previous Versions (`min_expertise_in_previous_versions`)\n",
    "\n",
    "    Definition: The smallest total number of commits among developers who have contributed to the target file in previous versions.\n",
    "    Collection Method:\n",
    "        Retrieve the total commits for each developer in previous versions.\n",
    "        Identify the minimum total commits among them.\n",
    "\n",
    "10. Average Time Between Commits in Version (`avg_time_between_commits_in_version`)\n",
    "\n",
    "    Definition: The average time (in seconds) between consecutive commits affecting the target file within the current version.\n",
    "    Collection Method:\n",
    "        Sort the commit timestamps of commits affecting the file in the current version.\n",
    "        Calculate the time differences between each pair of consecutive commits.\n",
    "        Compute the average of these time differences.\n",
    "\n",
    "11. Average Time Between Commits in Previous Versions (`avg_time_between_commits_in_previous_versions`)\n",
    "\n",
    "    Definition: The average time between consecutive commits affecting the target file in all previous versions.\n",
    "    Collection Method:\n",
    "        Sort the commit timestamps of commits affecting the file in previous versions.\n",
    "        Calculate the time differences between each pair of consecutive commits.\n",
    "        Compute the average of these time differences.\n",
    "\n",
    "12. Number of commits to file F during version V that have changed a code comment. (`num_commits_with_comment_changes`)\n",
    "\n",
    "    Definition: Number of commits to file F during version V that have changed a code comment.\n",
    "    Collection Method:\n",
    "        After retrieving the commits affecting the file in the current version, analyze \n",
    "        each commit to check if it changed a code comment.\n",
    "\n",
    "13. Number of commits to file F during version V that have not changed a code comment. (`num_commits_without_comment_changes`)\n",
    "\n",
    "    Definition: Number of commits to file F during version V that have not changed a code comment. \n",
    "    Collection Method:\n",
    "        After retrieving the commits affecting the file in the current version, analyze \n",
    "        each commit to check if it changed a code comment. The opposite metric as above.\n",
    "        It may be obtain by verifying the number of commits made in that version, and substracting the above metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by defining helper functions before defining metrics collection procedure and executing it all at once in order to speed up the process and minimize read-write operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_base_path = \"/home/nicolas-richard/Desktop/.Apache_Hive\"\n",
    "new_base_path = \"/home/nicolas/Desktop/hive\"\n",
    "\n",
    "def adjust_path(file_path):\n",
    "    # Check if the file path starts with the old base path\n",
    "    if file_path.startswith(old_base_path):\n",
    "        return new_base_path + file_path[len(old_base_path):]\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_version_from_filename(file_name):\n",
    "    match = re.search(r'(\\d+\\.\\d+\\.\\d+)', file_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    raise ValueError(f\"Version not found in file name: {file_name}\")\n",
    "\n",
    "def load_version_commits(version_commits_file):\n",
    "    \"\"\"Load version and commit mapping from a CSV file.\"\"\"\n",
    "    version_commits = []\n",
    "    with open(version_commits_file, mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            version_commits.append((row[0].strip(), row[1].strip()))\n",
    "    return version_commits\n",
    "\n",
    "def compare_versions(version1, version2):\n",
    "    \"\"\"Return True if version1 is less than or equal to version2.\"\"\"\n",
    "    v1 = list(map(int, version1.split('.')))\n",
    "    v2 = list(map(int, version2.split('.')))\n",
    "    return v1 <= v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll have to define metrics for developper experience. to simplify this, we can define this metric as total experience for the project. Hence, we can fetch all developpers having worked on the project and assign their experience as their numbers of commits on the project. While this way of defining experience is more than imperfect, the output gives us a solid base for the trainning to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "global developer_experiences \n",
    "\n",
    "def get_developer_experiences(repo):\n",
    "    \"\"\"Get total number of commits made by each developer in the entire project.\"\"\"\n",
    "    developer_experiences = defaultdict(int)\n",
    "    print(\"Fetching all commits in the repository for developer experiences...\")\n",
    "    for commit in repo.iter_commits():\n",
    "        developer = commit.author.email\n",
    "        developer_experiences[developer] += 1\n",
    "    return developer_experiences\n",
    "\n",
    "def calculate_expertise_metrics(commits):\n",
    "    \"\"\"Calculate expertise metrics from a list of commits.\"\"\"\n",
    "    developers = set(commit.author.email for commit in commits)\n",
    "    num_developers = len(developers)\n",
    "    expertise = {}\n",
    "    for developer in developers:\n",
    "        total_commits = developer_experiences.get(developer, 0)\n",
    "        expertise[developer] = total_commits\n",
    "    if expertise:\n",
    "        avg_expertise = sum(expertise.values()) / len(expertise)\n",
    "        min_expertise = min(expertise.values())\n",
    "    else:\n",
    "        avg_expertise = 0\n",
    "        min_expertise = 0\n",
    "    return num_developers, avg_expertise, min_expertise\n",
    "\n",
    "def calculate_time_metrics(commits):\n",
    "    \"\"\"Calculate average time between commits.\"\"\"\n",
    "    if len(commits) >= 2:\n",
    "        commit_dates = sorted([commit.committed_datetime for commit in commits])\n",
    "        time_diffs = [(commit_dates[i+1] - commit_dates[i]).total_seconds() for i in range(len(commit_dates)-1)]\n",
    "        avg_time_between_commits = sum(time_diffs) / len(time_diffs)\n",
    "    else:\n",
    "        avg_time_between_commits = None\n",
    "    return avg_time_between_commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the comments-related metrics, we can define the following pattern to identify whether a change to a file is a comment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comment_change(diff_text):\n",
    "    \"\"\"Determine if the diff includes changes to code comments.\"\"\"\n",
    "    # Define regex patterns for comment lines\n",
    "    comment_patterns = [\n",
    "        r'^\\s*//',       # C++/Java style single-line comment\n",
    "        r'^\\s*/\\*',      # Start of C-style multi-line comment\n",
    "        r'^\\s*\\*',       # Inside C-style multi-line comment\n",
    "        r'^\\s*\\*/',      # End of C-style multi-line comment\n",
    "    ]\n",
    "    pattern = re.compile('|'.join(comment_patterns))\n",
    "\n",
    "    for line in diff_text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line.startswith('+') or line.startswith('-'):\n",
    "            code_line = line[1:].strip()\n",
    "            if pattern.match(code_line):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentionned before, this task will be computationnaly very expensive. Hence, in order to minimize the quantity of git commands and read/write operations, we'll need to gather all of our metrics in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_metrics(hive_repo, version_commits, target_file_name, df_version):\n",
    "    \"\"\"Collect metrics for a target file.\"\"\"\n",
    "    global developer_experiences  \n",
    "    repo = git.Repo(hive_repo)\n",
    "    metrics = defaultdict(dict)\n",
    "\n",
    "    relevant_versions = [vc for vc in version_commits if compare_versions(vc[0], df_version)]\n",
    "\n",
    "    print(f\"Fetching all commits affecting {target_file_name}...\")\n",
    "    all_commits_affecting_file = list(repo.iter_commits(paths=target_file_name.strip()))\n",
    "\n",
    "    commit_to_version = {}\n",
    "    for i, (version, commit_hash) in enumerate(relevant_versions):\n",
    "        if i < len(relevant_versions) - 1:\n",
    "            next_commit_hash = relevant_versions[i + 1][1]\n",
    "        else:\n",
    "            next_commit_hash = 'HEAD'\n",
    "\n",
    "        commit_range = f\"{commit_hash}..{next_commit_hash}\"\n",
    "        commits_in_range = list(repo.iter_commits(commit_range))\n",
    "\n",
    "        for commit in commits_in_range:\n",
    "            commit_to_version[commit.hexsha] = version\n",
    "\n",
    "    version_to_commits = defaultdict(list)\n",
    "    for commit in all_commits_affecting_file:\n",
    "        commit_version = commit_to_version.get(commit.hexsha)\n",
    "        if commit_version:\n",
    "            version_to_commits[commit_version].append(commit)\n",
    "\n",
    "    all_previous_commits = []\n",
    "\n",
    "    for version in relevant_versions:\n",
    "        version = version[0]\n",
    "        commits_affecting_file = version_to_commits.get(version, [])\n",
    "\n",
    "        bug_fix_keywords = [\"fix\", \"bug\", \"issue\", \"HIVE-\"]\n",
    "        bug_fix_commits = [\n",
    "            c for c in commits_affecting_file if any(keyword in c.message.lower() for keyword in bug_fix_keywords)\n",
    "        ]\n",
    "\n",
    "        commits_with_comment_changes = []\n",
    "        commits_without_comment_changes = []\n",
    "        for commit in commits_affecting_file:\n",
    "            diffs = commit.diff(commit.parents[0] if commit.parents else None, paths=target_file_name.strip(), create_patch=True)\n",
    "            comment_change = False\n",
    "            for diff in diffs:\n",
    "                diff_text = diff.diff.decode('utf-8', errors='ignore')\n",
    "                if is_comment_change(diff_text):\n",
    "                    comment_change = True\n",
    "                    break\n",
    "            if comment_change:\n",
    "                commits_with_comment_changes.append(commit)\n",
    "            else:\n",
    "                commits_without_comment_changes.append(commit)\n",
    "\n",
    "        num_devs_in_version, avg_expertise_in_version, min_expertise_in_version = calculate_expertise_metrics(commits_affecting_file)\n",
    "\n",
    "        num_devs_in_prev_versions, avg_expertise_in_prev_versions, min_expertise_in_prev_versions = calculate_expertise_metrics(all_previous_commits)\n",
    "\n",
    "        avg_time_between_commits_in_version = calculate_time_metrics(commits_affecting_file)\n",
    "        avg_time_between_commits_in_previous_versions = calculate_time_metrics(all_previous_commits)\n",
    "\n",
    "        metrics[version] = {\n",
    "            \"num_commits_in_version\": len(commits_affecting_file),\n",
    "            \"num_bug_fix_commits\": len(bug_fix_commits),\n",
    "            \"num_commits_in_previous_versions\": len(all_previous_commits),\n",
    "            \"num_developers_in_version\": num_devs_in_version,\n",
    "            \"num_developers_in_previous_versions\": num_devs_in_prev_versions,\n",
    "            \"avg_expertise_in_version\": avg_expertise_in_version,\n",
    "            \"avg_expertise_in_previous_versions\": avg_expertise_in_prev_versions,\n",
    "            \"min_expertise_in_version\": min_expertise_in_version,\n",
    "            \"min_expertise_in_previous_versions\": min_expertise_in_prev_versions,\n",
    "            \"avg_time_between_commits_in_version\": avg_time_between_commits_in_version,\n",
    "            \"avg_time_between_commits_in_previous_versions\": avg_time_between_commits_in_previous_versions,\n",
    "            \"num_commits_with_comment_changes\": len(commits_with_comment_changes),\n",
    "            \"num_commits_without_comment_changes\": len(commits_without_comment_changes),\n",
    "        }\n",
    "\n",
    "        if version == df_version:\n",
    "            break\n",
    "        else:\n",
    "            all_previous_commits.extend(commits_affecting_file)\n",
    "            all_previous_commits = list({commit.hexsha: commit for commit in all_previous_commits}.values())\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def display_metrics(metrics):\n",
    "    \"\"\"Display metrics in a readable format.\"\"\"\n",
    "    for version, data in metrics.items():\n",
    "        print(f\"Version: {version}\")\n",
    "        print(f\"  - Commits affecting file in version: {data['num_commits_in_version']}\")\n",
    "        print(f\"  - Bug fix commits in version: {data['num_bug_fix_commits']}\")\n",
    "        print(f\"  - Commits in previous versions: {data['num_commits_in_previous_versions']}\")\n",
    "        print(f\"  - Number of Developers in version: {data['num_developers_in_version']}\")\n",
    "        print(f\"  - Number of Developers in previous versions: {data['num_developers_in_previous_versions']}\")\n",
    "        print(f\"  - Average Expertise in version: {data['avg_expertise_in_version']}\")\n",
    "        print(f\"  - Average Expertise in previous versions: {data['avg_expertise_in_previous_versions']}\")\n",
    "        print(f\"  - Minimum Expertise in version: {data['min_expertise_in_version']}\")\n",
    "        print(f\"  - Minimum Expertise in previous versions: {data['min_expertise_in_previous_versions']}\")\n",
    "        print(f\"  - Average Time Between Commits in version: {data['avg_time_between_commits_in_version']}\")\n",
    "        print(f\"  - Average Time Between Commits in previous versions: {data['avg_time_between_commits_in_previous_versions']}\")\n",
    "        print(f\"  - Commits with comment changes in version: {data['num_commits_with_comment_changes']}\")\n",
    "        print(f\"  - Commits without comment changes in version: {data['num_commits_without_comment_changes']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll define an overarching loop to gather all these metrics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "\n",
    "    version_commits_file = \"Hive_Last_Commits.csv\"\n",
    "\n",
    "    version_commits = load_version_commits(version_commits_file)\n",
    "    files_dir = os.path.join(project_repo, \"UND_hive_additional_metrics\")\n",
    "    files = sorted([\n",
    "        os.path.join(files_dir, f) \n",
    "        for f in os.listdir(files_dir) \n",
    "    ])\n",
    "\n",
    "    repo = git.Repo(hive_repo)\n",
    "    developer_experiences = get_developer_experiences(repo)\n",
    "\n",
    "    for file in files:\n",
    "        df_version = extract_version_from_filename(file)\n",
    "        print(f\"Extracted version: {df_version}\")\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"CommitsAffectingFileInCurrentVersion\"] = 0\n",
    "        df[\"CommitsFixingBugInFileInCurrentVersion\"] = 0\n",
    "        df[\"CommitsAffectingFileInPreviousVersions\"] = 0\n",
    "        df[\"NumDevelopersInVersion\"] = 0\n",
    "        df[\"NumDevelopersInPreviousVersions\"] = 0\n",
    "        df[\"AvgExpertiseInVersion\"] = 0.0\n",
    "        df[\"AvgExpertiseInPreviousVersions\"] = 0.0\n",
    "        df[\"MinExpertiseInVersion\"] = 0\n",
    "        df[\"MinExpertiseInPreviousVersions\"] = 0\n",
    "        df[\"AvgTimeBetweenCommitsInVersion\"] = 0\n",
    "        df[\"AvgTimeBetweenCommitsInPreviousVersions\"] = 0\n",
    "        df[\"CommitsWithCommentChanges\"] = 0\n",
    "        df[\"CommitsWithoutCommentChanges\"] = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            target_file_name = adjust_path(row[\"FileName\"])\n",
    "            try:\n",
    "                print(f\"\\n\\nVersion Metrics for {target_file_name} in version <= {df_version}\")\n",
    "                metrics = collect_metrics(hive_repo, version_commits, target_file_name.strip(), df_version)\n",
    "                display_metrics(metrics)\n",
    "\n",
    "                df.loc[index, \"CommitsAffectingFileInCurrentVersion\"] = metrics[df_version][\"num_commits_in_version\"]\n",
    "                df.loc[index, \"CommitsFixingBugInFileInCurrentVersion\"] = metrics[df_version][\"num_bug_fix_commits\"]\n",
    "                df.loc[index, \"CommitsAffectingFileInPreviousVersions\"] = metrics[df_version][\"num_commits_in_previous_versions\"]\n",
    "                df.loc[index, \"NumDevelopersInVersion\"] = metrics[df_version][\"num_developers_in_version\"]\n",
    "                df.loc[index, \"NumDevelopersInPreviousVersions\"] = metrics[df_version][\"num_developers_in_previous_versions\"]\n",
    "                df.loc[index, \"AvgExpertiseInVersion\"] = metrics[df_version][\"avg_expertise_in_version\"]\n",
    "                df.loc[index, \"AvgExpertiseInPreviousVersions\"] = metrics[df_version][\"avg_expertise_in_previous_versions\"]\n",
    "                df.loc[index, \"MinExpertiseInVersion\"] = metrics[df_version][\"min_expertise_in_version\"]\n",
    "                df.loc[index, \"MinExpertiseInPreviousVersions\"] = metrics[df_version][\"min_expertise_in_previous_versions\"]\n",
    "                df.loc[index, \"AvgTimeBetweenCommitsInVersion\"] = metrics[df_version][\"avg_time_between_commits_in_version\"]\n",
    "                df.loc[index, \"AvgTimeBetweenCommitsInPreviousVersions\"] = metrics[df_version][\"avg_time_between_commits_in_previous_versions\"]\n",
    "                df.loc[index, \"CommitsWithCommentChanges\"] = metrics[df_version][\"num_commits_with_comment_changes\"]\n",
    "                df.loc[index, \"CommitsWithoutCommentChanges\"] = metrics[df_version][\"num_commits_without_comment_changes\"]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {target_file_name}: {e}\")\n",
    "\n",
    "        df.to_csv(file, index=False)\n",
    "        print(f\"=== Updated file saved as {file} ===\\n\")\n",
    "    print(\"\\n\\n\\nCommit version processing successful\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
