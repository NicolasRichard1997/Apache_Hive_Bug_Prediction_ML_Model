{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additionnal Metrics\n",
    "As per the specification of the personnal project, we'll try and gather additionnal metrics to improve our model. Since this notebook is very compute-intensive, it was executed directly in the terminal after converting this notebook to a python file.\n",
    "## 1. Lines added & deleted from a given version\n",
    "We'll begin by creating a dictionnary of versions and corresponding commits from the file `Hive_Last_Commits.csv`previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "import pytz\n",
    "import git\n",
    "from typing import Iterable, Dict, Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_repo = Path(\"/home/nicolas-richard/Desktop/.Apache_Hive_Bug_Prediction_ML_Model/\")\n",
    "hive_repo = Path(\"/home/nicolas-richard/Desktop/.Apache_Hive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2.0.0   ': ['7f9f1fcb8697fb33f0edc2c391930a3728d247d7'], '2.0.1   ': ['e3cfeebcefe9a19c5055afdcbb00646908340694'], '2.1.0   ': ['9265bc24d75ac945bde9ce1a0999fddd8f2aae29'], '2.1.1   ': ['1af77bbf8356e86cabbed92cfa8cc2e1470a1d5c'], '2.2.0   ': ['da840b0f8fa99cab9f004810cd22abc207493cae'], '2.3.0   ': ['6f4c35c9e904d226451c465effdc5bfd31d395a0'], '2.3.1   ': ['7590572d9265e15286628013268b2ce785c6aa08'], '2.3.2   ': ['857a9fd8ad725a53bd95c1b2d6612f9b1155f44d'], '2.3.3   ': ['3f7dde31aed44b5440563d3f9d8a8887beccf0be'], '2.3.4   ': ['56acdd2120b9ce6790185c679223b8b5e884aaf2'], '2.3.5   ': ['76595628ae13b95162e77bba365fe4d2c60b3f29'], '2.3.6   ': ['2c2fdd524e8783f6e1f3ef15281cc2d5ed08728f'], '2.3.7   ': ['cb213d88304034393d68cc31a95be24f5aac62b6'], '2.3.8   ': ['f1e87137034e4ecbe39a859d4ef44319800016d7'], '2.3.9   ': ['92dd0159f440ca7863be3232f3a683a510a62b9d'], '2.3.10  ': ['5160d3af392248255f68e41e1e0557eae4d95273'], '3.0.0   ': ['ce61711a5fa54ab34fc74d86d521ecaeea6b072a'], '3.1.0   ': ['bcc7df95824831a8d2f1524e4048dfc23ab98c19'], '3.1.1   ': ['f4e0529634b6231a0072295da48af466cf2f10b7'], '3.1.2   ': ['8190d2be7b7165effa62bd21b7d60ef81fb0e4af'], '3.1.3   ': ['4df4d75bf1e16fe0af75aad0b4179c34c07fc975'], '4.0.0   ': ['183f8cb41d3dbed961ffd27999876468ff06690c'], '4.0.1   ': ['3af4517eb8cfd9407ad34ed78a0b48b57dfaa264']}\n"
     ]
    }
   ],
   "source": [
    "last_commits = open(os.path.join(project_repo, \"Hive_Last_Commits.csv\"), \"r\")\n",
    "\n",
    "versions = []\n",
    "commits_by_version = {}\n",
    "\n",
    "for i, line in enumerate(last_commits.readlines()):\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    parts = line.strip().split(\",\")\n",
    "    version = parts[0]\n",
    "    commit = parts[1]\n",
    "\n",
    "    versions.append(version)\n",
    "    commits_by_version[version] = [commit]  \n",
    "last_commits.close()\n",
    "\n",
    "print(commits_by_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UND_hive_updated_directory = project_repo / \"UND_hive_updated_data\"\n",
    "output_directory = project_repo / \"UND_hive_additional_metrics\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "csv_files = sorted([f for f in os.listdir(UND_hive_updated_directory) if f.endswith('.csv')])\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(UND_hive_updated_directory / file)\n",
    "    df_version = file.split(\"_\")[1]\n",
    "\n",
    "    print(f\"\\n=== Processing version: {df_version} ===\")\n",
    "\n",
    "    for another_file in csv_files:\n",
    "        another_version = another_file.split(\"_\")[1]\n",
    "    \n",
    "        df[f\"LinesAddedSince{another_version}\"] = 0\n",
    "        print(f\"LinesAddedSince{another_version} added to version {df_version}\")\n",
    "        df[f\"LinesRemovedSince{another_version}\"] = 0\n",
    "        print(f\"LinesRemovedSince{another_version} added to version {df_version}\")\n",
    "\n",
    "        if another_version >= df_version: \n",
    "            continue\n",
    "            \n",
    "        print(f\"  Comparing with earlier version: {another_version}\")\n",
    "        another_df = pd.read_csv(os.path.join(UND_hive_updated_directory, another_file))\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            file_name = row[\"FileName\"]\n",
    "            line_count = row[\"CountLine\"]\n",
    "\n",
    "            matching_rows = another_df[another_df[\"FileName\"] == file_name]\n",
    "\n",
    "            if not matching_rows.empty:\n",
    "                another_line_count = matching_rows.iloc[0][\"CountLine\"]\n",
    "                print(f\"    - {file_name} found in version {another_version}\")\n",
    "\n",
    "                if line_count > another_line_count:\n",
    "                    added_lines = line_count - another_line_count\n",
    "                    df.loc[index, f\"LinesAddedSince{another_version}\"] = added_lines\n",
    "                    print(f\"      Lines added: {added_lines}\")\n",
    "                elif line_count < another_line_count:\n",
    "                    removed_lines = another_line_count - line_count\n",
    "                    df.loc[index, f\"LinesRemovedSince{another_version}\"] = removed_lines\n",
    "                    print(f\"      Lines removed: {removed_lines}\")\n",
    "\n",
    "    output_path = output_directory / f\"UND_{df_version}.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"=== Updated file saved as {output_path} ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Commits Affecting the File in a Given version\n",
    "First, we'll fetch the `CommitsAffectingFileInCurrentVersion`, `CommitsFixingBugInFileInCurrentVersion`, `CommitsAffectingFileInPreviousVersions` variables and save them to our additionnal metrics files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"CommitsAffectingFileInCurrentVersion\" added to version 2.0.0\n",
      "\"CommitsFixingBugInFileInCurrentVersion\" added to version 2.0.0\n",
      "\"CommitsAffectingFileInPreviousVersions\" added to version 2.0.0\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/AccumuloConnectionParameters.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 1\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/AccumuloHiveConstants.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 1\n",
      "  - Bug fix commits in version: 1\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/AccumuloHiveRow.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 3\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/AccumuloStorageHandler.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 7\n",
      "  - Bug fix commits in version: 1\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/HiveAccumuloHelper.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 3\n",
      "  - Bug fix commits in version: 1\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/LazyAccumuloMap.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/LazyAccumuloRow.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/Utils.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 4\n",
      "  - Bug fix commits in version: 1\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/ColumnEncoding.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/ColumnMapper.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 3\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/ColumnMapping.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/ColumnMappingFactory.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 1\n",
      "  - Bug fix commits in version: 1\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/HiveAccumuloColumnMapping.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/HiveAccumuloMapColumnMapping.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 3\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/HiveAccumuloRowIdColumnMapping.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/HiveColumn.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/columns/InvalidColumnMappingException.java in version <= 2.0.0\n",
      "  - Commits affecting file in version: 0\n",
      "  - Bug fix commits in version: 0\n",
      "  - Commits in previous versions: 0\n",
      "\n",
      "\n",
      "\n",
      "Version Metrics for /home/nicolas-richard/Desktop/.Apache_Hive/accumulo-handler/src/java/org/apache/hadoop/hive/accumulo/mr/HiveAccumuloRecordReader.java in version <= 2.0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVersion Metrics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in version <= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhive_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion_commits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_file_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     display_metrics(metrics)\n\u001b[1;32m     90\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommitsAffectingFileInCurrentVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics[df_version][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_commits_in_version\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[33], line 30\u001b[0m, in \u001b[0;36mcollect_metrics\u001b[0;34m(hive_repo, version_commits, target_file_name, df_version)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     commits_affecting_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_commits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m..HEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError fetching commits for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/git/objects/commit.py:466\u001b[0m, in \u001b[0;36mCommit._iter_from_process_or_stream\u001b[0;34m(cls, repo, proc_or_stream)\u001b[0m\n\u001b[1;32m    464\u001b[0m readline \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mreadline\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m    468\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "version_commits_file = \"Hive_Last_Commits.csv\"\n",
    "\n",
    "def load_version_commits(version_commits_file):\n",
    "    \"\"\"Load version and commit mapping from a CSV file.\"\"\"\n",
    "    version_commits = []\n",
    "    with open(version_commits_file, mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  \n",
    "        for row in reader:\n",
    "            version_commits.append((row[0].strip(), row[1].strip()))\n",
    "    return version_commits\n",
    "\n",
    "def compare_versions(version1, version2):\n",
    "    \"\"\"Compare two semantic versions (e.g., 2.1.0 and 2.0.1).\"\"\"\n",
    "    v1 = list(map(int, version1.split('.')))\n",
    "    v2 = list(map(int, version2.split('.')))\n",
    "    return v1 <= v2\n",
    "\n",
    "def collect_metrics(hive_repo, version_commits, target_file_name, df_version):\n",
    "    \"\"\"Collect metrics for a target file.\"\"\"\n",
    "    repo = git.Repo(hive_repo)\n",
    "    metrics = defaultdict(dict)\n",
    "    all_previous_commits = []\n",
    "\n",
    "    for i, (version, commit_hash) in enumerate(version_commits):\n",
    "        if not compare_versions(version, df_version):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            commits_affecting_file = list(repo.iter_commits(f\"{commit_hash}..HEAD\", paths=target_file_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching commits for {target_file_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        bug_fix_keywords = [\"fix\", \"bug\", \"issue\", \"HIVE-\"]\n",
    "        bug_fix_commits = [\n",
    "            c for c in commits_affecting_file if any(keyword in c.message.lower() for keyword in bug_fix_keywords)\n",
    "        ]\n",
    "\n",
    "        if i > 0:\n",
    "            try:\n",
    "                previous_commit_hash = version_commits[i - 1][1]\n",
    "                previous_commits = list(repo.iter_commits(f\"{previous_commit_hash}..{commit_hash}\", paths=target_file_name))\n",
    "                all_previous_commits.extend(previous_commits)\n",
    "                all_previous_commits = list(set(all_previous_commits))  \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching previous commits for {target_file_name}: {e}\")\n",
    "                previous_commits = []\n",
    "\n",
    "        metrics[version] = {\n",
    "            \"num_commits_in_version\": len(commits_affecting_file),\n",
    "            \"num_bug_fix_commits\": len(bug_fix_commits),\n",
    "            \"num_commits_in_previous_versions\": len(all_previous_commits),\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def display_metrics(metrics):\n",
    "    \"\"\"Display metrics in a readable format.\"\"\"\n",
    "    for version, data in metrics.items():\n",
    "        print(f\"  - Commits affecting file in version: {data['num_commits_in_version']}\")\n",
    "        print(f\"  - Bug fix commits in version: {data['num_bug_fix_commits']}\")\n",
    "        print(f\"  - Commits in previous versions: {data['num_commits_in_previous_versions']}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    version_commits = load_version_commits(version_commits_file)\n",
    "    files = sorted([\n",
    "        os.path.join(project_repo, \"UND_hive_additional_metrics\", f) \n",
    "        for f in os.listdir(os.path.join(project_repo, \"UND_hive_additional_metrics\")) \n",
    "    ])\n",
    "\n",
    "    for file in files:\n",
    "        df_version = file.split(\"_\")[-1] \n",
    "        df = pd.read_csv(file)\n",
    "        df[\"CommitsAffectingFileInCurrentVersion\"] = 0\n",
    "        print(f'\"CommitsAffectingFileInCurrentVersion\" added to version {df_version}')\n",
    "        df[\"CommitsFixingBugInFileInCurrentVersion\"] = 0\n",
    "        print(f'\"CommitsFixingBugInFileInCurrentVersion\" added to version {df_version}')\n",
    "        df[\"CommitsAffectingFileInPreviousVersions\"] = 0\n",
    "        print(f'\"CommitsAffectingFileInPreviousVersions\" added to version {df_version}')\n",
    "\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            target_file_name = row[\"FileName\"]\n",
    "            try:\n",
    "                print(f\"\\n\\nVersion Metrics for {target_file_name} in version <= {df_version}\")\n",
    "                metrics = collect_metrics(hive_repo, version_commits, target_file_name.strip(), df_version)\n",
    "                display_metrics(metrics)\n",
    "\n",
    "                df.loc[index, \"CommitsAffectingFileInCurrentVersion\"] = metrics[df_version][\"num_commits_in_version\"]\n",
    "                df.loc[index, \"CommitsFixingBugInFileInCurrentVersion\"] = metrics[df_version][\"num_bug_fix_commits\"]\n",
    "                df.loc[index, \"CommitsAffectingFileInPreviousVersions\"] = metrics[df_version][\"num_commits_in_previous_versions\"]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {target_file_name}: {e}\")\n",
    "\n",
    "        df.to_csv(file, index=False)\n",
    "        print(f\"=== Updated file saved as {file} ===\\n\")\n",
    "    print(\"\\n\\n\\nCommit version processing successful\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
